{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "from json.decoder import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some variables\n",
    "\n",
    "GDP_path=os.getcwd()\n",
    "\n",
    "data_path=os.path.join(GDP_path, \"data\")\n",
    "split_data_path=os.path.join(GDP_path, \"split_seqs\")\n",
    "\n",
    "args={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joints (pairs of connected keypoints). ViTPose skeleton\n",
    "joints=[[0,5],\n",
    "        [0,6],\n",
    "        [5,6],\n",
    "        [5,7],\n",
    "        [7,9],\n",
    "        [6,8],\n",
    "        [8,10],\n",
    "        [11,12],\n",
    "        [5,11],\n",
    "        [6,12],\n",
    "        [11,13],\n",
    "        [13,15],\n",
    "        [12,14],\n",
    "        [14,16],\n",
    "        ]\n",
    "\n",
    "neck_idx=5\n",
    "hip_idx=11\n",
    "\n",
    "ref_kp=0 #nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all IDs in a JSON list\n",
    "def find_all_IDs(path_to_folder_with_json, JSON_list, seq_idx):\n",
    "    all_IDs=[]\n",
    "    for idx, json_frame in enumerate(JSON_list):\n",
    "            if idx in seq_idx:\n",
    "                frame_path=os.path.join(path_to_folder_with_json,json_frame)\n",
    "                data=[]\n",
    "                with open(frame_path, 'r') as f:\n",
    "                        try:\n",
    "                            data = json.load(f)\n",
    "                            for p in data:\n",
    "                                if p['track_id'] not in all_IDs:\n",
    "                                    all_IDs.append(p['track_id'])\n",
    "                        except JSONDecodeError:\n",
    "                            pass\n",
    "    return all_IDs\n",
    "\n",
    "def most_common_class(numbers):\n",
    "    counts = {}\n",
    "    for num in numbers:\n",
    "        if num in counts:\n",
    "            counts[num] += 1\n",
    "        else:\n",
    "            counts[num] = 1\n",
    "\n",
    "    max_count = max(counts.values())\n",
    "    max_nums = [num for num, count in counts.items() if count == max_count]\n",
    "\n",
    "    if len(max_nums) == 1:\n",
    "        return max(counts, key=counts.get)\n",
    "    else:\n",
    "        if -1 in max_nums:\n",
    "            return -1\n",
    "        elif 1 in max_nums:\n",
    "            return 1\n",
    "        elif 2 in max_nums:\n",
    "            return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features of person in a frame\n",
    "\n",
    "def features_of_joint(x1, y1, x2, y2, normalizator):\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "\n",
    "    angle = math.atan2(dy, dx)\n",
    "    sin_val = math.sin(angle)\n",
    "    cos_val = math.cos(angle)\n",
    "\n",
    "    longitud=np.sqrt(dx**2 + dy**2)\n",
    "    longitud=longitud/normalizator\n",
    "\n",
    "    return longitud, sin_val, cos_val\n",
    "\n",
    "def kps_dist_of_person (p_kps, normalizator):\n",
    "\n",
    "    ref_kp_x=p_kps[ref_kp][0]\n",
    "    ref_kp_y=p_kps[ref_kp][1]\n",
    "\n",
    "    p_features=[]\n",
    "    for kp in range(len(p_kps)):\n",
    "        if kp >= 5:\n",
    "            dx = p_kps[kp][0] - ref_kp_x\n",
    "            dy = p_kps[kp][1] - ref_kp_y\n",
    "\n",
    "            p_features.append(dx/normalizator)\n",
    "            p_features.append(dy/normalizator)\n",
    "   \n",
    "    return p_features\n",
    "\n",
    "\n",
    "def features_of_person (p_kps, type_of_features=\"long_angl\"):\n",
    "\n",
    "    avrg_neck_x = (p_kps[neck_idx][0] + p_kps[neck_idx+1][0])/2.0\n",
    "    avrg_neck_y = (p_kps[neck_idx][1] + p_kps[neck_idx+1][1])/2.0\n",
    "    avrg_hip_x = (p_kps[hip_idx][0] + p_kps[hip_idx+1][0])/2.0\n",
    "    avrg_hip_y = (p_kps[hip_idx][1] + p_kps[hip_idx+1][1])/2.0\n",
    "\n",
    "    normalizator=np.sqrt((avrg_neck_x-avrg_hip_x)**2 + (avrg_neck_y-avrg_hip_y)**2)\n",
    "\n",
    "    if type_of_features==\"long_angl\" or type_of_features==\"angl\":\n",
    "        p_features=[]\n",
    "        for i in range(len(joints)):\n",
    "            idx1 = joints[i][0]\n",
    "            idx2 = joints[i][1]\n",
    "            longitud, sin_val, cos_val = features_of_joint(p_kps[idx1][0],p_kps[idx1][1],p_kps[idx2][0],p_kps[idx2][1], normalizator)\n",
    "            if type_of_features==\"long_angl\":\n",
    "                p_features.append(longitud)\n",
    "            p_features.append(sin_val)\n",
    "            p_features.append(cos_val)\n",
    "    else:\n",
    "        p_features=kps_dist_of_person (p_kps, normalizator)\n",
    "\n",
    "\n",
    "    return p_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract seq_from_video\n",
    "\n",
    "def extract_seq_from_video(jsons_folder_path, output_seq_path, classes_counters, seq_duration=1, seq_fps=10, window_seconds=0.5, \n",
    "                           video_fps=30, type_of_features=\"angl\"):\n",
    "\n",
    "    video_pose_name=os.path.split(jsons_folder_path)[1]\n",
    "    video_name=video_pose_name[0:(len(video_pose_name)-5)]  \n",
    "\n",
    "    if type_of_features==\"long_angl\":\n",
    "        n_features_per_person=3*len(joints) \n",
    "    elif type_of_features==\"angl\":\n",
    "        n_features_per_person=2*len(joints)\n",
    "    else:\n",
    "        n_features_per_person=2*(12)\n",
    "\n",
    "\n",
    "    jsons_list=os.listdir(jsons_folder_path)\n",
    "    jsons_list.sort()\n",
    "\n",
    "    finaljsons_per_seq=seq_duration*seq_fps\n",
    "    videoframes_per_seq=seq_duration*video_fps\n",
    "    window=math.floor(video_fps*window_seconds)\n",
    "    one_frame_every=video_fps//seq_fps\n",
    "\n",
    "    frames_in_video=len(jsons_list)-1\n",
    "    n_seq=1+math.ceil((frames_in_video-videoframes_per_seq)/window)\n",
    "    \n",
    "    for seq in range(n_seq):\n",
    "\n",
    "        videoframe_start=1+seq*window\n",
    "        videoframe_finish=videoframe_start+videoframes_per_seq\n",
    "        framevideo_idx=list(range(videoframe_start,videoframe_finish))\n",
    "        every_framevideo_idx=[]\n",
    "        for i in framevideo_idx:\n",
    "            if (i-1)%one_frame_every ==0:\n",
    "                every_framevideo_idx.append(i)\n",
    "        IDs_in_seq=find_all_IDs(jsons_folder_path, jsons_list, every_framevideo_idx)\n",
    "        \n",
    "        for id in IDs_in_seq:\n",
    "            classes_of_ID_in_seq=[]\n",
    "            for frame_idx in every_framevideo_idx:\n",
    "                class_id_frame=-1\n",
    "                if frame_idx+1<=frames_in_video:\n",
    "                    frame_path=os.path.join(jsons_folder_path,jsons_list[frame_idx])\n",
    "                    with open(frame_path, 'r') as f:\n",
    "                        try:\n",
    "                            jsonframe_data = json.load(f)\n",
    "                            for p in jsonframe_data:\n",
    "                                if p['track_id']==id:\n",
    "                                    class_id_frame=p['class']\n",
    "                                    break\n",
    "                        except JSONDecodeError:\n",
    "                            pass\n",
    "                classes_of_ID_in_seq.append(class_id_frame)\n",
    "            seq_class=most_common_class(classes_of_ID_in_seq)\n",
    "            if seq_class != -1:\n",
    "                features_of_ID_in_seq=[]\n",
    "                for frame_idx in every_framevideo_idx:\n",
    "                    p_frame_features=np.zeros(n_features_per_person).tolist()\n",
    "                    if frame_idx+1<=frames_in_video:    \n",
    "                        frame_path=os.path.join(jsons_folder_path,jsons_list[frame_idx])\n",
    "                        with open(frame_path, 'r') as f:\n",
    "                            try:\n",
    "                                jsonframe_data = json.load(f) \n",
    "                                for p in jsonframe_data:\n",
    "                                    if p['track_id']==id:\n",
    "                                        p_frame_features=features_of_person(p['keypoints'], type_of_features=type_of_features)\n",
    "                            except JSONDecodeError:\n",
    "                                pass\n",
    "                    features_of_ID_in_seq.append(p_frame_features)\n",
    "\n",
    "                data_id_seq={}\n",
    "                data_id_seq['ID']=id\n",
    "                data_id_seq['class']=seq_class\n",
    "                data_id_seq['features']=features_of_ID_in_seq\n",
    "                \n",
    "                with open(os.path.join(output_seq_path,f\"{video_name}_seq_{seq+1}_id_{id}.json\"), \"w\") as f:\n",
    "                    # Serialize the list to JSON format\n",
    "                    json.dump(data_id_seq, f, indent=2)\n",
    "\n",
    "                if seq_class == 0:\n",
    "                    classes_counters['neutral']+=1\n",
    "                elif seq_class == 1:\n",
    "                    classes_counters['aggressive']+=1\n",
    "                else:\n",
    "                    classes_counters['victim']+=1\n",
    "                  \n",
    "    return classes_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all seqs\n",
    "\n",
    "#seq_fps = 30,15,10,6,5,3,2,1 (default: 10)\n",
    "\n",
    "def generate_all_seqs(data_path, split_data_path, args):\n",
    "\n",
    "    if args['use_peaceful']:\n",
    "        sub_data=[\"aggressive\",\"peaceful\"]\n",
    "        sub_idx=\"a+p\"\n",
    "    else:\n",
    "        sub_data=[\"aggressive\"]\n",
    "        sub_idx=\"a\"\n",
    "\n",
    "    if not os.path.exists(split_data_path):\n",
    "        os.makedirs(split_data_path)\n",
    "        number_of_runs=1\n",
    "    else:\n",
    "        number_of_runs=1+len(os.listdir(split_data_path))\n",
    "\n",
    "    run_name=\"run\"+str(number_of_runs)+\"_\"+sub_idx+\"_\"+args['type_of_features']+\"_\"+str(args['seq_duration'])+\"_\"+str(args['window_seconds'])\n",
    "    output_train_path=os.path.join(split_data_path,run_name,\"train\")\n",
    "    if not os.path.exists(output_train_path):\n",
    "        os.makedirs(output_train_path)\n",
    "    output_test_path=os.path.join(split_data_path,run_name,\"test\")\n",
    "    if not os.path.exists(output_test_path):\n",
    "        os.makedirs(output_test_path)\n",
    "\n",
    "    train_classes_counters={'neutral':0, 'aggressive':0, 'victim':0}\n",
    "    test_classes_counters={'neutral':0, 'aggressive':0, 'victim':0}\n",
    "    for sub in sub_data:\n",
    "        subdata_path=os.path.join(data_path,sub)    \n",
    "\n",
    "        videos_list=os.listdir(subdata_path)\n",
    "        \n",
    "        # Partition the number of videos\n",
    "        num_videos = len(videos_list)\n",
    "        num_videos_train = int(num_videos * args['train_split_percent'] / 100)\n",
    "\n",
    "        # Randomly shuffle video files list\n",
    "        videos_list.sort()\n",
    "        random.seed(5) \n",
    "        random.shuffle(videos_list)\n",
    "\n",
    "        for i in range(num_videos_train):\n",
    "            jsons_folder_path=os.path.join(subdata_path,videos_list[i],videos_list[i]+\"_pose\")\n",
    "            \n",
    "            train_classes_counters=extract_seq_from_video(jsons_folder_path, output_train_path, train_classes_counters,\n",
    "                                                          seq_duration=args['seq_duration'],seq_fps=10, \n",
    "                                                          window_seconds=args['window_seconds'], video_fps=30, \n",
    "                                                          type_of_features=args['type_of_features'])\n",
    "            \n",
    "        for i in range(num_videos_train, num_videos):\n",
    "            jsons_folder_path=os.path.join(subdata_path,videos_list[i],videos_list[i]+\"_pose\")\n",
    "            \n",
    "            test_classes_counters=extract_seq_from_video(jsons_folder_path, output_test_path, test_classes_counters,\n",
    "                                                         seq_duration=args['seq_duration'], seq_fps=10, \n",
    "                                                         window_seconds=args['window_seconds'], video_fps=30, \n",
    "                                                         type_of_features=args['type_of_features'])\n",
    "    print(\"Train => \",train_classes_counters)\n",
    "    print(\"Test => \",test_classes_counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train =>  {'neutral': 5206, 'aggressive': 1839, 'victim': 1003}\n",
      "Test =>  {'neutral': 1465, 'aggressive': 376, 'victim': 205}\n"
     ]
    }
   ],
   "source": [
    "args['seq_duration'] = 1 #in seconds\n",
    "args['type_of_features'] = \"dist\" #long_angl, angl, or dist\n",
    "args['window_seconds'] = 0.5 #in seconds\n",
    "args['use_peaceful'] = True\n",
    "args['train_split_percent'] = 80 #%\n",
    "\n",
    "\n",
    "generate_all_seqs(data_path, split_data_path, args)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnK4PHqqeP0DpN41KNEZA3",
   "mount_file_id": "1gauGdHHCErH4ao0JyWAKbzDDCKAWDFfS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "33c8d9a754d0064196bd0e4c5b27c31efd1d4faf3e18c11e5e29ef5acc0f2711"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
